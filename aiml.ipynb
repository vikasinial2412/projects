{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOdd4Vs9WsLEgNQdnc4Yeu2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vikasinial2412/projects/blob/main/aiml.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2S2tc2tA28om",
        "outputId": "ae55a12f-d657-46a3-bd41-f2f4005b1184"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 0us/step\n",
            "Epoch 1/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 65ms/step - accuracy: 0.3330 - loss: 1.8795 - val_accuracy: 0.4163 - val_loss: 1.6576\n",
            "Epoch 2/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 63ms/step - accuracy: 0.4353 - loss: 1.6088 - val_accuracy: 0.4667 - val_loss: 1.5027\n",
            "Epoch 3/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 65ms/step - accuracy: 0.4815 - loss: 1.4550 - val_accuracy: 0.4940 - val_loss: 1.4184\n",
            "Epoch 4/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 65ms/step - accuracy: 0.5245 - loss: 1.3518 - val_accuracy: 0.5105 - val_loss: 1.3723\n",
            "Epoch 5/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 67ms/step - accuracy: 0.5418 - loss: 1.2974 - val_accuracy: 0.5294 - val_loss: 1.3545\n",
            "Epoch 6/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 64ms/step - accuracy: 0.5658 - loss: 1.2310 - val_accuracy: 0.5316 - val_loss: 1.3326\n",
            "Epoch 7/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 64ms/step - accuracy: 0.5838 - loss: 1.1791 - val_accuracy: 0.5466 - val_loss: 1.2964\n",
            "Epoch 8/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 64ms/step - accuracy: 0.6004 - loss: 1.1301 - val_accuracy: 0.5485 - val_loss: 1.2974\n",
            "Epoch 9/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 65ms/step - accuracy: 0.6112 - loss: 1.0985 - val_accuracy: 0.5431 - val_loss: 1.3123\n",
            "Epoch 10/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 64ms/step - accuracy: 0.6290 - loss: 1.0502 - val_accuracy: 0.5459 - val_loss: 1.3005\n",
            "Epoch 11/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 66ms/step - accuracy: 0.6428 - loss: 1.0198 - val_accuracy: 0.5484 - val_loss: 1.3108\n",
            "Epoch 12/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 64ms/step - accuracy: 0.6519 - loss: 0.9785 - val_accuracy: 0.5357 - val_loss: 1.3187\n",
            "Epoch 13/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 65ms/step - accuracy: 0.6605 - loss: 0.9533 - val_accuracy: 0.5480 - val_loss: 1.3188\n",
            "Epoch 14/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 67ms/step - accuracy: 0.6709 - loss: 0.9277 - val_accuracy: 0.5536 - val_loss: 1.3242\n",
            "Epoch 15/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 65ms/step - accuracy: 0.6873 - loss: 0.8906 - val_accuracy: 0.5503 - val_loss: 1.3554\n",
            "Epoch 16/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 64ms/step - accuracy: 0.6940 - loss: 0.8664 - val_accuracy: 0.5543 - val_loss: 1.3620\n",
            "Epoch 17/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 63ms/step - accuracy: 0.7045 - loss: 0.8366 - val_accuracy: 0.5511 - val_loss: 1.3721\n",
            "Epoch 18/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 65ms/step - accuracy: 0.7093 - loss: 0.8167 - val_accuracy: 0.5471 - val_loss: 1.4134\n",
            "Epoch 19/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 67ms/step - accuracy: 0.7224 - loss: 0.7857 - val_accuracy: 0.5499 - val_loss: 1.3957\n",
            "Epoch 20/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 65ms/step - accuracy: 0.7323 - loss: 0.7624 - val_accuracy: 0.5446 - val_loss: 1.4272\n",
            "313/313 - 5s - 16ms/step - accuracy: 0.5446 - loss: 1.4272\n",
            "Test accuracy: 0.54\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "(x_train, y_train), (x_test, y_test) = datasets.cifar10.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "def build_lenet():\n",
        " model = models.Sequential()\n",
        " model.add(layers.Input(shape=(32, 32, 3)))\n",
        " model.add(layers.Conv2D(6, kernel_size=(5, 5), activation='tanh',\n",
        "padding='same'))\n",
        " model.add(layers.AveragePooling2D(pool_size=(2, 2)))\n",
        " model.add(layers.Conv2D(16, kernel_size=(5, 5), activation='tanh'))\n",
        " model.add(layers.AveragePooling2D(pool_size=(2, 2)))\n",
        " model.add(layers.Flatten())\n",
        " model.add(layers.Dense(120, activation='tanh'))\n",
        " model.add(layers.Dense(84, activation='tanh'))\n",
        " model.add(layers.Dense(10, activation='softmax'))\n",
        " return model\n",
        "model = build_lenet()\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy',\n",
        "metrics=['accuracy'])\n",
        "history = model.fit(x_train, y_train, epochs=20, batch_size=64,\n",
        "validation_data=(x_test, y_test))\n",
        "test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=2)\n",
        "print(f\"Test accuracy: {test_accuracy:.2f}\")"
      ]
    }
  ]
}